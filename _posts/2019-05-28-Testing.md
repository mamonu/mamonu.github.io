---
layout: single
title: "Testing"
header:
  overlay_image: https://github.com/mamonu/mamonu.github.io/raw/master/assets/hypt/QA__TE.jpg
  overlay_filter: 0.75
  teaser: https://github.com/mamonu/mamonu.github.io/raw/master/assets/hypt/QA__TE.jpg
date:   28-05-2019 06:58:07 +0000
---

### Testing 

<br /> 

Testing is an essential part of quality assuring our work when creating work that fits the Reproducible Analytical Pipelines (RAP) concept.
For more information about RAP please have a look below:

- [x] [Udemy Course for Using RAP with R](https://www.udemy.com/reproducible-analytical-pipelines/)
- [x] [The RAP companion](https://ukgovdatascience.github.io/rap_companion/)
- [x] [The RAP website](https://ukgovdatascience.github.io/rap-website/index.html)



So lets get started with some explanations of some concepts of testing:

<br /> 
#### Unit testing (basic anecdote-based testing)

  Anecdote based testing. Test your functions with specific inputs and expect specific outputs.
  Start with your testing here.  :)
  Unit tests are very low level, close to the source of your application. They focus on testing individual methods 
  and functions used by your scripts.
  
  There are very good testing frameworks that make the creation of tests convenient and not a drag.
  Pytest is recommended for Python (and testthat for R). There are also many Pytest plugins that add new functionality 
  such as coverage calculation, parallelizing tests,including time information in tests(ie fail a test if it takes more than 1 min to finish!) etc
  
<br /> 
#### Unit testing (automated with parameterization)

   Same as above but include more than one set of inputs and outputs. The more the merrier!!!
   Parametrized tests will be called multiple times, each time executing the set of dependent tests. 
   Test functions usually do not need to be aware of their re-running.
   
<br /> 
#### Integration testing (less tests that unit tests)  

  Integration tests verify that different functions or pipeline steps used by your application work well together. 
  So it is testing performed to expose defects in the interfaces and in the interactions between pipeline steps.
  Its important to do this for larger pipelines. Sometimes especially when different people create different steps of the pipeline and
  perhaps specification information is lost in translation (great movie by the way), this is a way to ensure .. integration!

<br /> 
#### End to End Testing (even less tests but to test whole pipeline)

  There may still be emergent issues when the whole pipeline is used together hence E2E testing needed. 

<br /> 
#### Things that are not essential but are 'Nice to Have' :
<br /> 
#### Continuous Integration

  Every time someone tries to integrate / add code to a codebase the following things need to happen:
  
  * merge new code with old code in a test environment
  * run a series of tests (many unit tests,less integration tests,few e2e tests)
  * if none of the tests is throwing an error then code is accepted to repo (or at least this is the point that perhaps code review can take place
  
  This is very useful for automatically checking your own work. Its immeasurably useful when 2 or more people collaborate on a codebase.
  
  
<br /> 
#### Coverage metrics (useful metric but not end-all-be-all)

  Coverage is a useful metric for code quality. It measures how much of your code has been used / executed through your tests.
By having as high coverage as possible you ensure that at least that part has been tested a bit! It is useful as a metric. But perhaps not as something to blindly adhere to. Ie you could have high coverage but the tests can be simple and not cover all eventualities









