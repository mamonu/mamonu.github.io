---
layout: single
title: "Testing"
header:
  overlay_image: https://github.com/mamonu/mamonu.github.io/raw/master/assets/hypt/QA_Glitch.gif
  overlay_filter: 0.75
  teaser: https://github.com/mamonu/mamonu.github.io/raw/master/assets/hypt/QA_Glitch.gif
date:   28-05-2019 06:58:07 +0000
---

## Testing: Because we can‚Äôt spell BUGS without U   üêû

<br /> 

Testing is a way of quality assuring our work when creating software that is important.
Quality means a lot of things and for the scope of this post I will mean reliability mainly. Martin Fowler has a [great](https://martinfowler.com/articles/is-quality-worth-cost.html) article on why high quality software is worth the effort.

Testing is an essential part for work that fits the Reproducible Analytical Pipelines (RAP) concept.
For more information about RAP , a great cross-government initiative please have a look below:

- [x] [Udemy Course for Using RAP with R](https://www.udemy.com/reproducible-analytical-pipelines/)
- [x] [The RAP companion](https://ukgovdatascience.github.io/rap_companion/)
- [x] [The RAP website](https://ukgovdatascience.github.io/rap-website/index.html)



So lets get started with some explanations of some concepts of testing:

<br /> 
### Unit testing 
<br /> 

  Test your functions with specific inputs and expect specific outputs.
  Start with your testing here.  üòä 
  Unit tests are  low level,focusing on testing individual methods and functions used by your scripts.
  
  There are very good testing frameworks that make the creation of tests convenient and not a drag.
  Pytest is recommended for Python (and testthat for R). There are also many Pytest plugins that add new functionality 
  such as coverage calculation, parallelizing tests,including time information in tests(ie fail a test if it takes more than 1 min to finish!) etc
  
<br /> 
### Unit testing (automated with parameterization)
<br /> 

   Same as above but include more than one set of inputs and outputs. The more the merrier!!!
   Parametrized tests will be called multiple times, each time executing the set of dependent tests. 
   Test functions usually do not need to be aware of their re-running.
   
<br /> 

### Integration testing (less tests that unit tests)  
<br /> 
  Integration tests verify that different functions or pipeline steps used by your application work well together. 
  So it is testing performed to expose defects in the interfaces and in the interactions between pipeline steps.
  Its important to do this for larger pipelines. Sometimes especially when different people create different steps of the pipeline and
  perhaps specification information is lost in translation (great movie by the way), this is a way to ensure .. integration!

<br /> 
### End to End Testing (even less tests but to test whole pipeline)
<br /> 
  There may still be emergent issues when the whole pipeline is used together hence E2E testing needed. 

<br /> 


### ... But will I need all this testing as a data scientist? I'm not creating enterprise software

<br /> 
You definately need to unit test the functions you are creating.
You dont need to test everything under the sun. Just your functions. Do lots of unit tests.  üòä 

When you are using loads of different functionality from different packages/different systems/different steps you can test this
and you could think of it as an integration test. Dont do a million of these. Just enough to show that what you think should happen should happen from one function to another.

Also in a pipeline perhaps you could test successive possible steps as an integration test. 

Finally it would be nice to have a few end-to-end tests from beggining to the end of a pipeline so you can perhaps catch things apparent only then! 

Certain data science languages like R or Python are not staticly-typed languages. This makes them sometimes easier but it does place the onus on the programmer to conduct more tests to ensure bugs are not introduced.What I am trying to say here is that in some other languages certain errors (related to wrong types) would not compile at all.

In Python and R there might be a chance to do so and this means that you rely more on your tests and less on the interpreter to make sure your code is correct.On the other hand Python and R are easier to use! 

So... you win on the swings and lose on the roundabouts üé°. 

There is [this](https://gist.github.com/non/ec48b0a7343db8291b92) discussion that is quite interesting about types. [Also this](https://pythonconquerstheuniverse.wordpress.com/2009/10/03/static-vs-dynamic-typing-of-programming-languages/) blog post which describes many languages and where they stand as far as the typing classification goes.Perhaps it will be of interest. 

PS. This is not a Python vs R vs $insertTrendyLanguge point. Both R/Python are great languages and help us perform a lot of great analytical work.It just helps to be aware of some of their weaker points so as to be prepared to deal with them.


### Things that are not essential but are 'Nice to Have' :
<br /> 
### Continuous Integration

  Every time someone tries to integrate / add code to a codebase the following things need to happen:
  
  * merge new code with old code in a test environment
  * run a series of tests (many unit tests,less integration tests,few e2e tests)
  * if none of the tests is throwing an error then code is accepted to repo (or at least this is the point that perhaps code review can take place)
  
  This is very useful for automatically checking your own work. Its immeasurably useful when 2 or more people collaborate on a codebase.
  
  
<br /> 
### Coverage  (useful metric but not end-all-be-all)
<br /> 

  Coverage is a useful metric for code quality. It measures how much of your code has been used / executed through your tests.
By having as high coverage as possible you ensure that at least that part has been tested a bit! It is useful as a metric. But perhaps not as something to blindly adhere to. Ie you could have high coverage but the tests can be simple and not cover all eventualities. One thing for sure is that it points out what has been NOT tested so in that sense its more useful :) 


### Further related reading if you are interested



- Some Books of interest (perhaps to find in local or organisation library) :

    
   [1][Software Tesiting](https://www.goodreads.com/book/show/25819310-software-testing)
  
   [2][Testing with Pytest](https://www.oreilly.com/library/view/python-testing-with/9781680502848/)
 

- Blog Posts


    [1][The Practical Test Pyramid](https://martinfowler.com/articles/practical-test-pyramid.html)
   

- Great course covering the spectrum of tools from the R side of things:
  
    [1][Reproducible Analytical Pipelines](https://www.udemy.com/reproducible-analytical-pipelines/)



- Article : When RAP processes are not there...

     [1][oops!](https://www.bbc.co.uk/news/magazine-22223190)
  
  
- Staticly-typed vs dynamicly-typed languages

    (perhaps dry subject... but some info here if you want to read about it.Btw Python is a strongly dynamicaly typed language and R is a weakly dynamicaly typed language) 
   
    [1][Types of many Languages](https://pythonconquerstheuniverse.wordpress.com/2009/10/03/static-vs-dynamic-typing-of-programming-languages/)

    [2] [Types in R](https://www.r-bloggers.com/practicing-static-typing-in-r-prime-directive-on-trusting-our-functions-with-object-oriented-programming/)

    [3] [nice discussion about types in languages](https://gist.github.com/non/ec48b0a7343db8291b92)









